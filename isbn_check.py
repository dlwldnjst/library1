import streamlit as st
import pandas as pd
import io
from io import StringIO
import re
import subprocess
import sys
import os

st.title("ISBN ì¤‘ë³µ ë„ì„œ ì§€ìš°ê°œ ï¢•")
# ë²„íŠ¼ ìŠ¤íƒ€ì¼ì˜ ë§í¬ ì¶”ê°€
st.markdown(
    """
    <a href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBAz3g%2FbtsJwqOEUO0%2FtoZvMwgk0F4XpPzg21lEjK%2Fimg.png" target="_blank" style="text-decoration: none;">
        <br>
        <div style="
            display: inline-block;
            padding: 8px 12px;
            font-size: 14px;
            font-weight: bold;
            color: white;
            background-color: #00418a;
            border-radius: 5px;
            text-align: center;">
            ğŸ“˜ ë…ì„œë¡œì—ì„œ ISBNì´ í¬í•¨ëœ ì†Œì¥ë„ì„œëª©ë¡ ë‹¤ìš´ë°›ëŠ” ë°©ë²•
        </div>
        <br>
        <br>
    </a>
    <br>
    """,
    unsafe_allow_html=True
)

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ë° ì„¤ì¹˜
# required_packages = ['html5lib', 'lxml', 'bs4']
# for package in required_packages:
#     try:
#         __import__(package)
#     except ImportError:
#         st.warning(f"{package} íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤...")
#         subprocess.check_call([sys.executable, "-m", "pip", "install", package])
#         st.success(f"{package} íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í—¤ë”(ì»¬ëŸ¼ëª…)ê°€ ì²« í–‰ì— ìˆë‹¤ê³  ê°€ì • (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)
skiprows_lib = 0
skiprows_pur = 0

# íŒŒì¼ ì—…ë¡œë“œ
lib_file = st.file_uploader("ì†Œì¥ ë„ì„œ ëª©ë¡ íŒŒì¼ ì—…ë¡œë“œ (.xls ë˜ëŠ” .xlsx)", type=["xls", "xlsx"])
pur_file = st.file_uploader("êµ¬ë§¤ ì˜ˆì • íŒŒì¼ ì—…ë¡œë“œ (.xls ë˜ëŠ” .xlsx)", type=["xls", "xlsx"])

st.markdown(
    "<hr>êµ¬ë§¤ ì˜ˆì • íŒŒì¼ì„ ì—…ë¡œë“œí•  ë•Œ ì˜¤ë¥˜ê°€ ë‚  ê²½ìš°, í™•ì¥ìë¥¼ xlsì—ì„œ xlsxë¡œ ì €ì¥ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.<br><br>ë¬¸ì˜: dlwldnjst@gmail.com<br><hr>",
    unsafe_allow_html=True
)

def extract_first_table(html_text):
    """ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•´ ì²« ë²ˆì§¸ <table>...</table> ë¸”ë¡ ì¶”ì¶œ"""
    pattern = re.compile(r'(<table.*?</table>)', re.DOTALL | re.IGNORECASE)
    match = pattern.search(html_text)
    if match:
        return match.group(1)
    return None

def read_uploaded_file(file, skiprows=0):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ì„ ë¨¼ì € pd.read_excelë¡œ ì½ì–´ë³´ê³ , ì‹¤íŒ¨ ì‹œ(ì˜ˆ: HTML í˜•ì‹ì¸ ê²½ìš°)
    íŒŒì¼ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©í•˜ì—¬ pd.read_html (ë˜ëŠ” ì¶”ì¶œëœ <table> ë¸”ë¡) ë°©ì‹ìœ¼ë¡œ DataFrameìœ¼ë¡œ ë³€í™˜.
    íŒŒì¼ í™•ì¥ìê°€ xls ë˜ëŠ” xlsxì¸ ê²½ìš° ìš°ì„  ì—‘ì…€ íŒŒì¼ë¡œ ì½ìŠµë‹ˆë‹¤.
    """
    try:
        content = file.getvalue()
    except Exception as e:
        st.error(f"íŒŒì¼ ë‚´ìš©ì„ ì½ì–´ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()
    
    file_extension = file.name.split('.')[-1].lower()
    
    # ìš°ì„  Excel íŒŒì¼ë¡œ ì½ì–´ë³´ê¸°
    if file_extension in ['xls', 'xlsx']:
        try:
            if file_extension == 'xls':
                df = pd.read_excel(io.BytesIO(content), engine='xlrd', skiprows=skiprows)
            else:
                df = pd.read_excel(io.BytesIO(content), engine='openpyxl', skiprows=skiprows)
            return df
        except Exception as excel_error:
            st.warning(f"Excel íŒŒì¼ë¡œ ì½ê¸° ì‹¤íŒ¨: {excel_error}")
            st.info("Excel íŒŒì¼ ì½ê¸°ì— ì‹¤íŒ¨í•˜ì—¬ HTML ë³€í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤.")
    
    # Excel ì½ê¸°ê°€ ì‹¤íŒ¨í–ˆê±°ë‚˜ íŒŒì¼ í˜•ì‹ì´ ë‹¤ë¥¸ ê²½ìš°, í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©í•˜ì—¬ HTML ë°©ì‹ìœ¼ë¡œ ì‹œë„
    try:
        content_text = content.decode('utf-8-sig', errors='ignore')
    except Exception as e:
        st.error(f"íŒŒì¼ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()
    
    # HTML íƒœê·¸ ì—¬ë¶€ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    if re.search(r'<html|<table|<tr|<td', content_text, re.IGNORECASE):
        st.info("HTML í˜•ì‹ì˜ íŒŒì¼ë¡œ ê°ì§€ë˜ì–´ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        html_parsers = ['html5lib', 'lxml', 'bs4']
        df_list = None
        for parser in html_parsers:
            try:
                df_list = pd.read_html(StringIO(content_text), flavor=parser)
                if df_list and len(df_list) > 0:
                    st.info(f"{parser} íŒŒì„œë¡œ í…Œì´ë¸”ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    break
            except Exception as e:
                st.warning(f"{parser} íŒŒì„œë¡œ HTML ì½ê¸° ì‹¤íŒ¨: {e}")
                continue
        
        # pd.read_htmlë¡œ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ì²« ë²ˆì§¸ <table> ë¸”ë¡ ì¶”ì¶œ í›„ ë‹¤ì‹œ ì‹œë„
        if not df_list or len(df_list) == 0:
            st.info("pd.read_htmlë¡œ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ <table> ë¸”ë¡ì„ ì¶”ì¶œí•˜ì—¬ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
            table_html = extract_first_table(content_text)
            if table_html:
                try:
                    df_list = pd.read_html(StringIO(table_html), flavor='html5lib')
                except Exception as e:
                    st.error(f"ì¶”ì¶œëœ HTML ë¸”ë¡ìœ¼ë¡œ í…Œì´ë¸” ì½ê¸° ì‹¤íŒ¨: {e}")
            else:
                st.error("HTMLì—ì„œ <table> íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if df_list and len(df_list) > 0:
            # ê°€ì¥ í° í…Œì´ë¸” ì„ íƒ (í–‰*ì—´ ìˆ˜ê°€ ìµœëŒ€ì¸ í…Œì´ë¸”)
            largest_df = max(df_list, key=lambda df: df.shape[0] * df.shape[1])
            return largest_df
        else:
            raise ValueError("HTML í…Œì´ë¸”ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # HTML íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°, CSV í˜•ì‹ìœ¼ë¡œ ì‹œë„
        try:
            return pd.read_csv(StringIO(content_text))
        except Exception as csv_error:
            st.warning(f"CSV í˜•ì‹ìœ¼ë¡œ ì½ê¸° ì‹¤íŒ¨: {csv_error}")
        
        raise ValueError("íŒŒì¼ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§€ì›ë˜ëŠ” í˜•ì‹ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")

def drop_rows_with_mostly_empty(df, threshold=0.8):
    """
    ê° í–‰ì—ì„œ ì „ì²´ ì…€ ì¤‘ ë¹ˆ ê°’(ë˜ëŠ” ê³µë°± ë¬¸ìì—´)ì˜ ë¹„ìœ¨ì´ threshold ì´ìƒì´ë©´ í•´ë‹¹ í–‰ì„ ì œê±°í•©ë‹ˆë‹¤.
    
    Args:
        df (pd.DataFrame): ì…ë ¥ ë°ì´í„°í”„ë ˆì„
        threshold (float): ì œê±° ê¸°ì¤€ ë¹„ìœ¨ (ì˜ˆ: 0.8ì´ë©´ 80% ì´ìƒ ë¹ˆ ì…€ì´ë©´ ì œê±°)
        
    Returns:
        pd.DataFrame: í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
    """
    n_cols = df.shape[1]
    
    def is_empty(val):
        # NaNì´ê±°ë‚˜ ë¬¸ìì—´ì˜ ê²½ìš° ê³µë°±ë¬¸ìë§Œ ìˆë‹¤ë©´ ë¹ˆ ê°’ìœ¼ë¡œ ê°„ì£¼
        if pd.isna(val):
            return True
        if isinstance(val, str) and val.strip() == "":
            return True
        return False

    mask = df.apply(lambda row: sum(is_empty(cell) for cell in row) / n_cols < threshold, axis=1)
    return df[mask].copy()

if lib_file is not None and pur_file is not None:
    # ì†Œì¥ ë„ì„œ ëª©ë¡ ì½ê¸°
    try:
        lib_df = read_uploaded_file(lib_file, skiprows=skiprows_lib)
    except Exception as e:
        st.error(f"ì†Œì¥ ë„ì„œ ëª©ë¡ íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()
    
    # êµ¬ë§¤ ì˜ˆì • íŒŒì¼ ì½ê¸°
    try:
        pur_df = read_uploaded_file(pur_file, skiprows=skiprows_pur)
    except Exception as e:
        st.error(f"êµ¬ë§¤ ì˜ˆì • íŒŒì¼ì„ ì½ì–´ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì»¬ëŸ¼ëª…ì€ ê·¸ëŒ€ë¡œ, ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°ë§Œ í‘œì‹œ)
    st.subheader("ì†Œì¥ ë„ì„œ ëª©ë¡ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(lib_df.head())

    st.subheader("êµ¬ë§¤ ì˜ˆì • ëª©ë¡ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(pur_df.head())
    
    # ISBN ì»¬ëŸ¼ ì„ íƒ: 'ISBN13'ì´ ìˆìœ¼ë©´ ìš°ì„  ì„ íƒ
    st.subheader("ì†Œì¥ ë„ì„œ ëª©ë¡ì˜ ISBN(ë˜ëŠ” ISBN13) ì»¬ëŸ¼ ì„ íƒ")
    def get_default_isbn_col(df):
        cols = df.columns.tolist()
        if "ISBN13" in cols:
            return "ISBN13"
        elif "ISBN" in cols:
            return "ISBN"
        else:
            return cols[0]
    
    default_lib_isbn = get_default_isbn_col(lib_df)
    lib_isbn_col = st.selectbox("ì†Œì¥ ë„ì„œ ëª©ë¡ì—ì„œ ISBN ì»¬ëŸ¼ ì„ íƒ", 
                                options=lib_df.columns.tolist(),
                                index=lib_df.columns.tolist().index(default_lib_isbn))
    
    st.subheader("êµ¬ë§¤ ì˜ˆì • ëª©ë¡ì˜ ISBN(ë˜ëŠ” ISBN13) ì»¬ëŸ¼ ì„ íƒ")
    default_pur_isbn = get_default_isbn_col(pur_df)
    pur_isbn_col = st.selectbox("êµ¬ë§¤ ì˜ˆì • ëª©ë¡ì—ì„œ ISBN ì»¬ëŸ¼ ì„ íƒ", 
                                options=pur_df.columns.tolist(),
                                index=pur_df.columns.tolist().index(default_pur_isbn))
    
#    st.subheader("êµ¬ë§¤ ì˜ˆì • ëª©ë¡ì˜ ê°€ê²© ì»¬ëŸ¼ ì„ íƒ (ì„ íƒ ì‚¬í•­)")
#    price_col_options = ["ì„ íƒ ì•ˆ í•¨"] + pur_df.columns.tolist()
#    default_price_col_index = 0
#    for i, col_name in enumerate(price_col_options):
#        if col_name in ["ê°€ê²©", "ê¸ˆì•¡", "Price", "price", "AMOUNT", "Amount"]: # Common price column names
#            default_price_col_index = i
#            break
#    price_col = st.selectbox("ê°€ê²© ì»¬ëŸ¼ (í•©ê³„ ê³„ì‚° ë° í˜•ì‹ ìœ ì§€ìš©)", 
#                             options=price_col_options,
#                             index=default_price_col_index,
#                             key="price_column_selector")
    
    # ISBN ì •ì œ í•¨ìˆ˜: ì¢Œìš° ê³µë°± ì œê±°, í•˜ì´í”ˆ ì œê±°, ëŒ€ë¬¸ì ë³€í™˜ ë“±
    def clean_isbn(series):
        cleaned = series.astype(str).str.strip().str.replace("-", "", regex=False).str.upper()
        cleaned = cleaned.replace("NAN", "").replace("", pd.NA)
        return cleaned

    if st.button("ISBN ì¤‘ë³µ ê²€ì‚¬"):
        # ISBN ì •ì œ ì ìš©
        lib_df[lib_isbn_col] = clean_isbn(lib_df[lib_isbn_col])
        pur_df[pur_isbn_col] = clean_isbn(pur_df[pur_isbn_col])

        # ì†Œì¥ ë„ì„œ ëª©ë¡ì€ ISBNì´ ìœ íš¨í•œ (13ìë¦¬) í–‰ë§Œ ë‚¨ê¹€
        lib_isbn_valid = lib_df[lib_isbn_col].astype(str).str.len() == 13
        lib_df = lib_df[lib_isbn_valid].dropna(subset=[lib_isbn_col])

        # (ì‹ ê·œ) ì„ íƒëœ ê°€ê²© ì»¬ëŸ¼ ì •ì œ
        #if price_col != "ì„ íƒ ì•ˆ í•¨" and price_col in pur_df.columns:
        #    try:
        #        # ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì •ì œí•´ì•¼ ë‹¤ì–‘í•œ ì…ë ¥ í˜•ì‹ì— ëŒ€ì‘ ê°€ëŠ¥
        #        temp_price_series = pur_df[price_col].astype(str)
        #        # ì‰¼í‘œ ì œê±°
        #        temp_price_series = temp_price_series.str.replace(',', '', regex=False)
        #        # ìˆ«ì, ì†Œìˆ˜ì , ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ì™¸ ëª¨ë“  ë¬¸ì ì œê±°
        #        temp_price_series = temp_price_series.str.replace(r'[^\d.\-]', '', regex=True)
        #        # ìˆ«ì íƒ€ì…ìœ¼ë¡œ ë³€í™˜, ë³€í™˜ ë¶ˆê°€ ì‹œ NaT/NaN ì²˜ë¦¬
        #        pur_df[price_col] = pd.to_numeric(temp_price_series, errors='coerce')
        #        st.success(f"'{price_col}' ì»¬ëŸ¼ì„ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        #    except Exception as e:
        #        st.warning(f"'{price_col}' ì»¬ëŸ¼ì„ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›ë³¸ ë°ì´í„°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")

        # ì¤‘ë³µ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ISBN ì‹ë³„ (ì†Œì¥ ëª©ë¡ì— ìˆëŠ” ISBN)
        pur_df_isbn_not_na = pur_df[pur_isbn_col].notna()
        pur_df_isbn_valid_len = pur_df[pur_isbn_col].astype(str).str.len() == 13
        pur_df_isbn_in_lib = pur_df[pur_isbn_col].isin(lib_df[lib_isbn_col])
        mask_potential_duplicates = pur_df_isbn_not_na & pur_df_isbn_valid_len & pur_df_isbn_in_lib
        
        potential_duplicates_df = pur_df[mask_potential_duplicates]
        isbns_to_actually_remove = []

        if not potential_duplicates_df.empty:
            st.subheader("ì¤‘ë³µ ISBN ì„ íƒí•˜ì—¬ ì œì™¸")
            st.warning(f"ì†Œì¥ ë„ì„œ ëª©ë¡ê³¼ ì¤‘ë³µë˜ëŠ” ISBNì´ êµ¬ë§¤ ì˜ˆì • ëª©ë¡ì— {len(potential_duplicates_df)}ê±´ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ëª©ë¡ì—ì„œ 'ì œì™¸í•˜ê¸°'ë¥¼ ì„ íƒí•˜ì—¬ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            display_duplicates_df = potential_duplicates_df.copy()
            # 'ì œì™¸í•˜ê¸°' ì»¬ëŸ¼ì„ ë§¨ ì•ì— ì¶”ê°€í•˜ê³  ê¸°ë³¸ê°’ì„ True (ì œì™¸í•¨)ë¡œ ì„¤ì •
            display_duplicates_df.insert(0, 'ì œì™¸í•˜ê¸°', True)
            
            edited_duplicates_df = st.data_editor(
                display_duplicates_df,
                disabled=potential_duplicates_df.columns.tolist(), # ì›ë³¸ ë°ì´í„° ì»¬ëŸ¼ë“¤ì€ ìˆ˜ì • ë¶ˆê°€
                key="duplicate_selection_editor",
                hide_index=True
            )
            
            isbns_to_actually_remove = edited_duplicates_df[edited_duplicates_df['ì œì™¸í•˜ê¸°']][pur_isbn_col].tolist()
            
            if isbns_to_actually_remove:
                st.info(f"ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ {len(isbns_to_actually_remove)}ê±´ì˜ ì¤‘ë³µ ë„ì„œë¥¼ ì œê±°í•©ë‹ˆë‹¤.")
            else:
                st.info("ì‚¬ìš©ìê°€ ëª¨ë“  ì¤‘ë³µ ì˜ì‹¬ ë„ì„œë¥¼ ìœ ì§€í•˜ë„ë¡ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ì†Œì¥ ë„ì„œ ëª©ë¡ê³¼ ì¤‘ë³µë˜ëŠ” ISBNì´ êµ¬ë§¤ ì˜ˆì • ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤.")

        # ìµœì¢… output_df ìƒì„±: ì„ íƒëœ ì¤‘ë³µ ISBN ì œê±°
        if isbns_to_actually_remove:
            final_removal_mask = pur_df[pur_isbn_col].isin(isbns_to_actually_remove)
            output_df = pur_df[~final_removal_mask].copy()
        else:
            output_df = pur_df.copy() 
        
        removed_count = pur_df.shape[0] - output_df.shape[0]
        if removed_count > 0:
            st.success(f"ì´ {removed_count}ê¶Œì˜ ì¤‘ë³µ ë„ì„œê°€ ìµœì¢…ì ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif not potential_duplicates_df.empty and not isbns_to_actually_remove:
             st.success("ì¤‘ë³µì´ ë°œê²¬ë˜ì—ˆìœ¼ë‚˜, ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ ì œê±°ëœ ë„ì„œëŠ” ì—†ìŠµë‹ˆë‹¤.")
        # else: # ì¤‘ë³µ ì—†ìŒ, ì´ë¯¸ ìœ„ì—ì„œ ë©”ì‹œì§€ ì²˜ë¦¬

        # ë¶ˆí•„ìš”í•œ ë¹ˆ í–‰ ì œê±° (ì „ì²´ ì…€ì˜ 50% ì´ìƒì´ ë¹ˆ í–‰ ì œê±°)
        output_df = drop_rows_with_mostly_empty(output_df, threshold=0.5)
        
        # ë²ˆí˜¸(ìˆœë²ˆ) ì¹¼ëŸ¼ ì¬ì„¤ì •
        output_df.reset_index(drop=True, inplace=True)
        if "ìˆœë²ˆ" in output_df.columns:
            output_df["ìˆœë²ˆ"] = range(1, len(output_df) + 1)
        else:
            output_df.insert(0, "ìˆœë²ˆ", range(1, len(output_df) + 1))
        
        st.subheader("ìµœì¢… êµ¬ë§¤ ì˜ˆì • ëª©ë¡ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(output_df)
        
        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬ (ê²°ê³¼ëŠ” XLSX í˜•ì‹, ì›ë³¸ êµ¬ë§¤ ì˜ˆì • ëª©ë¡ê³¼ ë™ì¼í•œ í˜•ì‹)
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            output_df.to_excel(writer, index=False)
        buffer.seek(0)
        
        st.download_button(
            label="í•„í„°ë§ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=buffer,
            file_name="filtered_purchase_list.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# ì „ì—­ ë°©ë¬¸ì ìˆ˜(ì¹´ìš´í„°)ë¥¼ íŒŒì¼ì— ì €ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.
# ì´ íŒŒì¼ì€ ì•±ì˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ìƒì„±ë˜ë©°, ì™¸ë¶€ ì‚¬ìš©ìëŠ” ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
counter_file = "visitor_counter.txt"
if not os.path.exists(counter_file):
    with open(counter_file, "w") as f:
        f.write("0")

# íŒŒì¼ì„ ì½ì–´ í˜„ì¬ ì¹´ìš´íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê³ , ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
with open(counter_file, "r+") as f:
    count_str = f.read().strip()
    try:
        count = int(count_str)
    except:
        count = 0
    count += 1
    f.seek(0)
    f.write(str(count))
    f.truncate()

# í˜ì´ì§€ ì œì¼ í•˜ë‹¨ì— ë°©ë¬¸ì ìˆ˜(ì¹´ìš´í„°)ë¥¼ í°ìƒ‰ ê¸€ì”¨ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
# ì´ ê¸€ì”¨ëŠ” ë°°ê²½ê³¼ ë™ì¼í•œ í°ìƒ‰ì´ë¯€ë¡œ ì¼ë°˜ ì‚¬ìš©ìëŠ” ë³´ì´ì§€ ì•Šê³ , ê°œë°œìë§Œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
st.markdown(
    f"<div style='color: white; font-size: 10px; text-align: center;'>ì´ ë°©ë¬¸ì ìˆ˜: {count}</div>",
    unsafe_allow_html=True
)
